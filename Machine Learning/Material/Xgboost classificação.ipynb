{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXRL1XXTR/IA9SSVExQ+gD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#XGBoost\n","---\n","**Aula Prática 09**: XGBoost para classificação\n","\n","\n","**Objetivo**: Treinar modelo de classificação\n","\n","\n","Banco de dados:\n","\n","\n","**Breast cancer wisconsin dataset**\n","\n","\n","Disponível via sklearn\n","\n","\n","> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.\n",">\n","> 1) ID number\n",">\n","> 2) Diagnosis (0 = malignant, 1 = benign)\n",">\n","> 3-32)\n",">\n","> Ten real-valued features are computed for each cell nucleus:\n",">\n","> a) radius (mean of distances from center to points on the perimeter)\n",">\n","> b) texture (standard deviation of gray-scale values)\n",">\n","> c) perimeter\n",">\n","> d) area\n",">\n","> e) smoothness (local variation in radius lengths)\n",">\n","> f) compactness (perimeter^2 / area - 1.0)\n",">\n","> g) concavity (severity of concave portions of the contour)\n",">\n","> h) concave points (number of concave portions of the contour)\n",">\n","> i) symmetry\n",">\n","> j) fractal dimension (\"coastline approximation\" - 1)"],"metadata":{"id":"zxHUgPSFM1fc"}},{"cell_type":"markdown","source":["##Import das principais funções e leitura dos dados\n","\n","\n","---\n","\n"],"metadata":{"id":"w1NLIkJMRP4U"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import datasets"],"metadata":{"id":"Wfg5H5k7QUoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = datasets.load_breast_cancer()"],"metadata":{"id":"cz13V0q4Q5ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(data.data, columns=data.feature_names)"],"metadata":{"id":"39H8czgiIvdT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target = pd.DataFrame(data.target, columns=['Target'])\n","df = pd.concat([df, target], axis=1)"],"metadata":{"id":"do_VDG4RJICz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"gE2hH2_8SHHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"K94v4s0lSNC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"iyj0P08tSR5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe().T"],"metadata":{"id":"D4JMYa2ZJSto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Treino de modelo de decision tree\n","---\n","\n","\n","Para treinar um modelo de regressão utilizaremos o pacote sklearn.\n","\n","\n","### Separação do banco entre treino e teste\n","O primeiro passo para se treinar um modelo é separar o banco entre treino e teste. Para isso utilizaremos a função train_test_split\n","\n","\n","``` python\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n","```\n","No exemplo acima X é um dataframe contendo as features do modelo e Y um dataframe com a variável target.\n","\n","\n","O parâmetro test_size controla o percentual de dados que será utilizado para teste.\n","\n","\n","O parâmetro random_state controla a aleatoriedade da geração do dado, permitindo que ao reexecutar o código seja gerado os mesmos bancos de treino e teste.\n","\n","\n","É importante separar o banco entre treino e teste, pois utilizaremos o banco de treino para treinar modelos e o banco de teste para avaliar os modelos.\n","\n","\n","### Treino do modelo\n","Agora que já possuímos os dados de treino e teste vamos treinar o nosso modelo XGBoost\n","\n","\n","``` python\n","from xgboost import XGBClassifier\n","model = XGBClassifier(objective='binary:logistic')\n","model.fit(X_train, Y_train)\n","```\n","\n","No código acima o objeto model é do tipo XGBClassifier, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado a árvore e a importancia das features.\n","\n","\n","``` python\n","# Para fazer predições de classes\n","model.predict(X_test)\n","# Para fazer predições de probabilidade\n","model.predict_proba(X_test)\n","# Para acessar a importancia\n","model.feature_importances_\n","\n","```\n","\n","Alguns parâmetros da XGBClassifier:\n","* max_depth: profundidade da árvore. Default é 6.\n","* seed: semente para aleatoriedade.\n","* n_estimators*: número de árvores para construir. Default é 100.\n","* subsample: número de instancias para amostrar.\n","* colsample_bytree: número de colunas para amostrar ao construir uma árvore. Também é possível por level e por nó.\n","* objective: tipo de função de perda.\n","* learning_rate**: parâmetro de aprendizado do modelo. Quanto menor o valor mais árvores são necessarias. Default: 0.3\n","\n","\n","### Avaliação do modelo\n","Para avaliar o modelo treinado utilizaremos as métricas vistas na aula teórica.\n","\n","``` python\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay\n","\n","\n","# Métricas acurácia, precisão, recall, f1-score\n","print(classification_report(Y_test, Y_predit))\n","\n","\n","# Matriz de confusão\n","confusion_matrix(Y_test, Y_predit)\n","\n","\n","# AUC\n","roc_auc = roc_auc_score(Y_test, Y_predict)\n","fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n","display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n","display.plot()\n","```\n","\n","\n","Também é possível se obter cada uma das métricas do report\n","``` python\n","from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n","\n","\n","recall_score(Y_test, Y_predict, pos_label=1)\n","```\n","\n","\n","### Primeiro modelo\n","\n","---\n","\n","Exercício:\n","\n","\n","* Separe o banco entre treino e teste. Use 30% do banco para teste. Faça a quebra com todas as variáveis.\n","* Treine um modelo.\n","* Faça as análises de apuração do modelo\n"],"metadata":{"id":"M9mSwwoqRbef"}},{"cell_type":"code","source":["X = pd.DataFrame(data.data, columns=data.feature_names)\n","Y = data.target"],"metadata":{"id":"G4pgJuxgN_XX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solução"],"metadata":{"id":"idl1fuKB-1TJ"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)"],"metadata":{"id":"djHH_xBsT-0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_train.mean()"],"metadata":{"id":"_nAxgZq8OCio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"fXfocudAOD-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"kcmF8ckROFv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","model = XGBClassifier(objective='binary:logistic')\n","model.fit(X_train, Y_train)"],"metadata":{"id":"q7bp0j7kOJax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay"],"metadata":{"id":"bIuyZ_VxOhQC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_class = model.predict(X_test)"],"metadata":{"id":"IxU_skYOOsXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(Y_test, pred_class))"],"metadata":{"id":"AZ72bQ8qOp2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import recall_score"],"metadata":{"id":"RLnF6yJ5PEs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["recall_score(Y_test, pred_class)"],"metadata":{"id":"xc5qRXEWPHna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["recall_score(Y_test, pred_class, pos_label=0)"],"metadata":{"id":"Zi7rMBoFPKw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(Y_test, pred_class)"],"metadata":{"id":"KrtWNg2cO9Mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["roc_auc = roc_auc_score(Y_test, pred_class)\n","roc_auc"],"metadata":{"id":"zQwyRGnnPB0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fpr, tpr, thresholds = roc_curve(Y_test, pred_class)\n","display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n","display.plot()"],"metadata":{"id":"_J3ljOhyPpkx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercício:\n","* Treine um novo modelo porém com max_depth = 4\n","* Busca o limiar em que se obtém a melhor acurácia.\n","\n","Dica:\n","Para realizar a busca faça:\n","1. Gere o score de probabilidade\n","2. Percorra uma lista de valores de limiar e a cada valor calcule a acurácia\n","3. Obtenha o limiar com maior acurácia\n","\n","\n","Para acessar P(Y=1) faça predict_proba()[:, 1]"],"metadata":{"id":"sztPnLqBUBm4"}},{"cell_type":"markdown","source":["#### Solução"],"metadata":{"id":"265K8AE9UgWU"}},{"cell_type":"code","source":["model = XGBClassifier(objective='binary:logistic', max_depth=4)\n","model.fit(X_train, Y_train)"],"metadata":{"id":"WSS9gsnAqkFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_proba = model.predict_proba(X_test)"],"metadata":{"id":"0PjrAU7mVGc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_proba"],"metadata":{"id":"dn_8t6vgVTAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","predict_proba = model.predict_proba(X_test)[:, 1]\n","acc_atual = 0\n","thr_otimo = 0\n","for thr in np.arange(0, 1, .1):\n","  acc = accuracy_score(Y_test, predict_proba>=thr)\n","  if acc >= acc_atual:\n","    thr_otimo = thr\n","    acc_atual = acc"],"metadata":{"id":"QsAVnXpUUg_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc_atual"],"metadata":{"id":"G_4uCmksVU4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["thr_otimo"],"metadata":{"id":"RlXQDlKSVV-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import plotly.express as px\n","\n","acc_lista = []\n","for thr in np.arange(0, 1, .1):\n","  acc_lista.append(accuracy_score(Y_test, predict_proba>=thr))\n","\n","px.line(x=np.arange(0, 1, .1), y=acc_lista)"],"metadata":{"id":"VZCmqIVCVdK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(Y_test, predict_proba>=.4))"],"metadata":{"id":"tvW0RNsVSlSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(Y_test, predict_proba>=.9))"],"metadata":{"id":"7TTZ8WUOSt9O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Visualização da feature importance**"],"metadata":{"id":"92XsDKG0rGC2"}},{"cell_type":"code","source":["df = pd.DataFrame(model.feature_importances_.T, index=data.feature_names, columns=['Importancia'])\n","df.sort_values('Importancia', ascending=False)"],"metadata":{"id":"mPM9tPBGrv9H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.bar(df.sort_values('Importancia'))"],"metadata":{"id":"K9v9YUWYsWd0"},"execution_count":null,"outputs":[]}]}