{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUC Minas\n",
    "### Pós-Graduação em Ciência de Dados e Big Data\n",
    "#### Avaliação Final - Modelagem e Preparação de Dados para Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aluno(s):**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:51.870133Z",
     "start_time": "2024-05-03T19:20:51.867908Z"
    }
   },
   "source": "# Luciano Augusto Scherer Contri",
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriçao de Atributos**\n",
    "\n",
    "- age: idade\n",
    "- workclass: classe de trabalho\n",
    "- education: nível educacional\n",
    "- education-num: anos de educação\n",
    "- marital-status: estado civil\n",
    "- occupation: profissão\n",
    "- race: etnia\n",
    "- sex: gênero\n",
    "- capital-gain: ganho de capital\n",
    "- capital-loss: perda de capital\n",
    "- hours-per-week: horas de trabalho por semana\n",
    "- native-country: país de origem\n",
    "\n",
    "**Contexto dos Dados**\n",
    "\n",
    "O dataset apresenta dados de um problema de classificação onde o objetivo é prever se a pessoa da observação ganha mais de 50k dólares por ano ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.008396Z",
     "start_time": "2024-05-03T19:20:52.005755Z"
    }
   },
   "source": [
    "# Carregue o dataset fornecido ('adult_final.csv')"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.085371Z",
     "start_time": "2024-05-03T19:20:52.038914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "        \n",
    "adult_final = pd.read_csv('../../Datasets/adult_final.csv', sep = ',')\n",
    "adult_final"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Apresente o tipo das variáveis.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.115575Z",
     "start_time": "2024-05-03T19:20:52.111396Z"
    }
   },
   "source": "adult_final.dtypes",
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Apresente de forma gráfica e numérica a análise exploratória das variáveis _education_ e _race_.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.400859Z",
     "start_time": "2024-05-03T19:20:52.148607Z"
    }
   },
   "source": "adult_final['education'].value_counts().plot(kind='bar')",
   "execution_count": 66,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.407618Z",
     "start_time": "2024-05-03T19:20:52.401861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# porcentagem \n",
    "adult_final['education'].value_counts(normalize=True) * 100"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.549401Z",
     "start_time": "2024-05-03T19:20:52.408620Z"
    }
   },
   "cell_type": "code",
   "source": "adult_final['race'].value_counts().plot(kind='bar')",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.556573Z",
     "start_time": "2024-05-03T19:20:52.550409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# porcentagem\n",
    "adult_final['race'].value_counts(normalize=True) * 100"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Apresente as métricas estatísticas (média, moda, etc.) e histograma das variáveis _age_ e _hours-per-week_.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.566588Z",
     "start_time": "2024-05-03T19:20:52.556573Z"
    }
   },
   "source": [
    "# agregações\n",
    "adult_final.agg({'age': ['mean', 'median', 'std', 'var', 'min', 'max'], 'hours-per-week': ['mean', 'median', 'std', 'var', 'min', 'max']})"
   ],
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Apresente 2 análises multivaridas entre variáveis a sua escolha.**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.577751Z",
     "start_time": "2024-05-03T19:20:52.567591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# média de idade por classe de trabalho\n",
    "adult_final.groupby('workclass')[['capital-gain', 'age']].mean().sort_values(by='age')"
   ],
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.585785Z",
     "start_time": "2024-05-03T19:20:52.578752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# média de horas por semana por classe de trabalho\n",
    "adult_final.groupby('workclass')['hours-per-week'].mean().sort_values()"
   ],
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.593936Z",
     "start_time": "2024-05-03T19:20:52.585785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# média de horas por semana por ocupação\n",
    "adult_final.groupby('occupation')['hours-per-week'].mean().sort_values()"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.606856Z",
     "start_time": "2024-05-03T19:20:52.599942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# workclass por média de idade\n",
    "adult_final.groupby('workclass')['age'].mean().sort_values()"
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.639201Z",
     "start_time": "2024-05-03T19:20:52.630879Z"
    }
   },
   "source": [
    "# média de education-num por target\n",
    "adult_final.groupby('workclass')['education-num'].mean().sort_values()"
   ],
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Apresente a soma de _NaN_ de cada coluna da base de dados.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:20:52.851796Z",
     "start_time": "2024-05-03T19:20:52.816175Z"
    }
   },
   "source": "adult_final.isna().sum()",
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Trate os _NaN_ de todas as colunas como achar conveniente (explique). Em seguida, mostre que nenhuma coluna apresenta _NaN_ ao final do processo.**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como as colunas são categoricas, não podemos substituir os valores faltantes pela média ou mediana, pois não faz sentido.   \n",
    "podemos substituir os valores faltantes pela moda, ou seja, o valor mais frequente. \n",
    "Mas isso pode enviesar o modelo, pois a moda pode não ser a melhor escolha para substituir os valores faltantes.\n",
    "Outra opção é usar o KNNImputer, que é um método de imputação que utiliza os k vizinhos mais próximos para preencher os valores faltantes."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### KNN"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T01:35:26.997478Z",
     "start_time": "2024-05-04T01:35:26.084042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "# Carregar e preparar o DataFrame\n",
    "df = adult_final.copy()\n",
    "num_cols = ['education-num', 'age', 'capital-gain', 'hours-per-week']\n",
    "cat_cols = ['workclass', 'occupation', 'native-country']\n",
    "\n",
    "# hashmap para workclass em ordem crescente\n",
    "workclass_map = {'Federal-gov': 1, 'Local-gov': 2, 'State-gov': 3, 'Self-emp-inc': 4, 'Self-emp-not-inc': 5, 'Private': 6, 'Without-pay': 7, 'Never-worked': 8}\n",
    "\n",
    "occupation_map = {'Prof-specialty': 1, 'Exec-managerial': 2, 'Protective-serv': 3, 'Tech-support': 4, 'Sales': 5, 'Craft-repair': 6, 'Transport-moving': 7, 'Adm-clerical': 8, 'Farming-fishing': 9, 'Machine-op-inspct': 10, 'Handlers-cleaners': 11, 'Other-service': 12, 'Armed-Forces': 13, 'Priv-house-serv': 14}\n",
    "\n",
    "native_country_map = {'United-States': 1, 'Mexico': 2, 'Philippines': 3, 'Germany': 4, 'Puerto-Rico': 5, 'Canada': 6, 'El-Salvador': 7, 'India': 8, 'Cuba': 9, 'England': 10, 'Jamaica': 11, 'South': 12, 'China': 13, 'Italy': 14, 'Dominican-Republic': 15, 'Vietnam': 16, 'Guatemala': 17, 'Japan': 18, 'Poland': 19, 'Columbia': 20, 'Taiwan': 21, 'Haiti': 22, 'Iran': 23, 'Portugal': 24, 'Nicaragua': 25, 'Peru': 26, 'Greece': 27, 'Ecuador': 28, 'France': 29, 'Ireland': 30, 'Hong': 31, 'Cambodia': 32, 'Trinadad&Tobago': 33, 'Thailand': 34, 'Laos': 35, 'Yugoslavia': 36, 'Outlying-US(Guam-USVI-etc)': 37, 'Honduras': 38, 'Hungary': 39, 'Scotland': 40, 'Holand-Netherlands': 41}\n",
    "\n",
    "# transformar workclass em ordem crescente\n",
    "df['workclass'] = df['workclass'].map(workclass_map)\n",
    "df['occupation'] = df['occupation'].map(occupation_map)\n",
    "df['native-country'] = df['native-country'].map(native_country_map)\n",
    "\n",
    "for i in cat_cols:\n",
    "    # Separe os dados em conjunto de treinamento e teste\n",
    "    train_df, test_df = train_test_split(df[num_cols + cat_cols].dropna(), test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Treine um modelo de classificação (por exemplo, KNN) usando os dados de treinamento\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_classifier.fit(train_df.drop(columns=[i]), train_df[i])  # 'workclass' é sua coluna alvo\n",
    "    \n",
    "    # Avalie a acurácia do modelo usando os dados de teste imputados\n",
    "    y_true = test_df[i]  # 'workclass' é sua coluna alvo\n",
    "    y_pred = knn_classifier.predict(test_df.drop(columns=[i]))  # 'workclass' é sua coluna alvo\n",
    "    # Calcular balanced_accuracy_score\n",
    "    \n",
    "    accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Acurácia do modelo imputado {i}: {accuracy:.3f}\")"
   ],
   "execution_count": 144,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Acurácia do modelo imputado workclass: 0.692\n",
    "Acurácia do modelo imputado occupation: 0.227\n",
    "Acurácia do modelo imputado native-country: 0.918\n",
    "\n",
    "Tendo em vista que os dados faltantes são menores que 10% do total, podemos usar o KNNImputer para preencher os valores faltantes."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 129,
   "source": "",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:15:24.148242Z",
     "start_time": "2024-05-03T20:15:21.308653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 130,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:15:47.864560Z",
     "start_time": "2024-05-03T20:15:47.857619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# comparing the original and imputed values to see how many changed with a sum\n",
    "(df[cat_cols] != adult_final[cat_cols]).sum()"
   ],
   "execution_count": 131,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:15:52.656798Z",
     "start_time": "2024-05-03T20:15:52.652874Z"
    }
   },
   "cell_type": "code",
   "source": "df['workclass'].unique()",
   "execution_count": 132,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ta perfeito demais pra ser verdade, mas pode ser apenas porquê o dataset é pequeno. de qualquer forma, vamos imputar os valores faltantes no dataset original."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:23:19.782245Z",
     "start_time": "2024-05-03T19:23:19.763321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imputar no dataset original   \n",
    "df_imputed = adult_final.copy()\n",
    "df_imputed[num_cols + cat_cols] = imputer.fit_transform(df[num_cols + cat_cols])\n",
    "# Decodificar as colunas categóricas imputadas para os valores originais\n",
    "for col in cat_cols:\n",
    "    df_imputed[col] = encoders[col].inverse_transform(df_imputed[col].astype(int))\n"
   ],
   "execution_count": 86,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:12:49.131751Z",
     "start_time": "2024-05-03T20:12:49.101469Z"
    }
   },
   "cell_type": "code",
   "source": "df.isna().sum()",
   "execution_count": 126,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:08:57.723559Z",
     "start_time": "2024-05-03T20:08:57.713139Z"
    }
   },
   "cell_type": "code",
   "source": "df[['workclass', 'occupation', 'native-country']].eq('Desconhecido').sum()\n",
   "execution_count": 122,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:06:45.246740Z",
     "start_time": "2024-05-03T19:06:45.230417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decodificar as colunas categóricas imputadas para os valores originais\n",
    "for col in cat_cols:\n",
    "    df_imputed[col] = encoders[col].inverse_transform(df_imputed[col].astype(int))\n",
    "\n",
    "# Verificar se a decodificação foi bem-sucedida\n",
    "df_imputed"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:06:45.278938Z",
     "start_time": "2024-05-03T19:06:45.246740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tabela unica de nunique() onde index é o nome da coluna e as colunas são os valores únicos de cada dataframe\n",
    "pd.concat([adult_final.nunique(), df_imputed.nunique()], axis=1, keys=['adult_final', 'df_imputed'])"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Podemos ver que o número de valores únicos aumentou em 1 pois o encoder adicionou um valor para os valores faltantes. como demonstrado abaixo."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:06:45.287924Z",
     "start_time": "2024-05-03T19:06:45.279940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# adult_final.nunique() e df_imputed.nunique() para verificar se o número de valores únicos é o mesmo, lado a lado\n",
    "print(adult_final['workclass'].unique()) \n",
    "print(adult_final['workclass'].nunique())\n",
    "print(df_imputed['workclass'].unique())\n",
    "print(df_imputed['workclass'].nunique())"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Aplique _Ordinal Encoding_ em uma variável categórica ordinal.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:06:45.304702Z",
     "start_time": "2024-05-03T19:06:45.287924Z"
    }
   },
   "source": [
    "# ordinal encoding na coluna 'education'\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "df_imputed['education'] = OrdinalEncoder().fit_transform(df_imputed[['education']])\n",
    "df_imputed['education']"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Aplique _One Hot Encoding_ em uma variável categórica nominal.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:06:45.318513Z",
     "start_time": "2024-05-03T19:06:45.305704Z"
    }
   },
   "source": [
    "# categorias nominais: workclass, occupation e native-country\n",
    "\n",
    "# one hot encoding na coluna 'workclass'\n",
    "df_imputed = pd.get_dummies(df_imputed, columns=['workclass']) "
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:09:45.982594Z",
     "start_time": "2024-05-03T19:09:45.977899Z"
    }
   },
   "cell_type": "code",
   "source": "df_imputed['workclass_nan']",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Aplique uma técnica de _oversampling_ (classe minoritária) e uma de _undersampling_ (classe majoritária). Apresente a mudança de volumetria (antes e depois). Se necessário, lembre-se de tratar as variáveis categóricas de forma adequada caso deseje usar um método mais robusto (SMOTE, por exemplo). Se for o caso, utilize PCA para visualizar os dados de forma bidimensional (antes e depois da amostragem).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Aplique _One Hot Encoding_ nas variáveis _race_ e _sex_. Junte ao resultado _TODAS_ as outras variáveis númericas (_age_, _education-num_, _capital-gain_, _capital-loss_ e _hours-per-week_). Utilize o dataset resultante no algoritmo t-SNE e reduza a dimensionalidade à 2 componentes (padrão do algoritmo). Plote o resultado diferenciando os pontos pela classe (atributo _target_).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2a75fef46bed89e0d903baa6d9759c336dac2ebed8fb5037eddcc41453e49ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
