{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FRAMEWORKS DE DEEPLEARNING**\n",
        "# **Prática - Keras**\n",
        "**Autor**: Renan Santos Mendes\n",
        "\n",
        "**Email**: renansantosmendes@gmail.com\n",
        "\n",
        "**Descrição**: Este notebook apresenta um exemplo de uma rede neural profunda com mais de uma camada para um problema de classificação.\n",
        "\n",
        "\n",
        "# **Saúde Fetal**\n",
        "\n",
        "As Cardiotocografias (CTGs) são opções simples e de baixo custo para avaliar a saúde fetal, permitindo que os profissionais de saúde atuem na prevenção da mortalidade infantil e materna. O próprio equipamento funciona enviando pulsos de ultrassom e lendo sua resposta, lançando luz sobre a frequência cardíaca fetal (FCF), movimentos fetais, contrações uterinas e muito mais.\n",
        "\n",
        "Este conjunto de dados contém 2126 registros de características extraídas de exames de Cardiotocografias, que foram então classificados por três obstetras especialistas em 3 classes:\n",
        "\n",
        "- Normal\n",
        "- Suspeito\n",
        "- Patológico"
      ],
      "metadata": {
        "id": "yYryuRDeqbxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install autokeras mlflow dagshub"
      ],
      "metadata": {
        "id": "9uLluT6aZth4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Importando os módulos necessários"
      ],
      "metadata": {
        "id": "4WgsLeJngPb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, InputLayer, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l1, l2\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import random as python_random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "55YREGWfhXuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definindo funções adicionais"
      ],
      "metadata": {
        "id": "NFTzaAkEr-IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_convergence(hist, metric):\n",
        "\n",
        "  df = pd.DataFrame(hist.history)\n",
        "  fig = px.line(df,\n",
        "                x=np.arange(df[metric].shape[0]),\n",
        "                y=[f'{metric}', f'val_{metric}'])\n",
        "  fig.show()\n",
        "\n",
        "def reset_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(42)\n",
        "   tf.random.set_seed(42)\n",
        "   np.random.seed(42)\n",
        "   random.seed(42)"
      ],
      "metadata": {
        "id": "OgKUlrlbozyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Fazendo a leitura do dataset e atribuindo às respectivas variáveis"
      ],
      "metadata": {
        "id": "I5uGdrdeh0QG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/renansantosmendes/lectures-cdas-2023/master/fetal_health.csv')"
      ],
      "metadata": {
        "id": "95168wcThmD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "rqn7E8l_XTNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Preparando o dado antes de iniciar o treino do modelo"
      ],
      "metadata": {
        "id": "1eQEA-fzgQ0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.drop([\"fetal_health\"], axis=1)\n",
        "y=data[\"fetal_health\"] - 1\n",
        "\n",
        "columns_names = list(X.columns)\n",
        "X_df = preprocessing.StandardScaler().fit_transform(X)\n",
        "X_df = pd.DataFrame(X_df, columns=columns_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df,\n",
        "                                                    y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train)\n",
        "y_test=keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "jBK7SgPxh7YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Criando o modelo e adicionando as camadas"
      ],
      "metadata": {
        "id": "54CmcOG1gRn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "model ..."
      ],
      "metadata": {
        "id": "4y2kKy_EkLGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Compilando o modelo\n"
      ],
      "metadata": {
        "id": "E0JmDrz6iQDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "7IeY0b4i1gQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Executando o treino do modelo"
      ],
      "metadata": {
        "id": "MoHbKkvCim-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "hist = ..."
      ],
      "metadata": {
        "id": "w8IX2tHI2VX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Avaliando o modelo"
      ],
      "metadata": {
        "id": "0pqwOl0Oc7nE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Plotando a acurácia do modelo"
      ],
      "metadata": {
        "id": "dEfh_F2NdMS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "x90V9p6lMDWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DagsHub\n",
        "<img src=\"https://api.flatworld.co/wp-content/uploads/2020/10/DAGsHub-Logo.png\" height=100>\n",
        "\n",
        "\n",
        "DagsHub é uma plataforma de colaboração e compartilhamento de código voltada para a comunidade de Ciência de Dados e Machine Learning. É uma plataforma que permite que os desenvolvedores, cientistas de dados e pesquisadores compartilhem seus projetos, coletem feedback de outros usuários, colaborem em projetos em equipe e gerenciem seu fluxo de trabalho de desenvolvimento de forma mais eficiente.\n",
        "\n",
        "A plataforma é baseada em Git e Git-LFS, o que significa que o controle de versão e o gerenciamento de arquivos são suportados nativamente. Além disso, o DagsHub oferece uma série de recursos adicionais que visam melhorar a experiência de desenvolvimento de projetos de Ciência de Dados e Machine Learning, como integração com ferramentas de treinamento de modelos, ambientes de execução, Jupyter notebooks e fluxos de trabalho de DAGs (gráficos acíclicos direcionados).\n",
        "\n",
        "\n",
        "Com o DagsHub, os usuários podem compartilhar seus projetos publicamente ou limitar o acesso a equipes específicas, criando uma comunidade de colaboração de dados e Machine Learning mais ampla. A plataforma também incentiva a colaboração em projetos de código aberto, com recursos para facilitar a contribuição e a revisão de código pelos usuários.\n",
        "\n",
        "Em resumo, o DagsHub é uma plataforma completa para compartilhamento, colaboração e gerenciamento de projetos de Ciência de Dados e Machine Learning, que tem como objetivo tornar o trabalho em equipe mais fácil e eficiente para os usuários.\n",
        "\n",
        "### [Link](https://dagshub.com/) para acesso."
      ],
      "metadata": {
        "id": "YKZtrzVuNaY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mlflow dagshub"
      ],
      "metadata": {
        "id": "t-QNqjomNayr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import dagshub\n",
        "\n",
        "mlflow.tensorflow.autolog()\n",
        "# dagshub.init(\"seu_repositorio\",\"seu_username\")"
      ],
      "metadata": {
        "id": "ShSp4GXzNdxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjIFYH54VdKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vendo a arquitetura do modelo**"
      ],
      "metadata": {
        "id": "PtUwuRnffvch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "QYjObnbZfuIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model=model,\n",
        "           show_shapes=True,\n",
        "           show_dtype=True,\n",
        "           show_layer_names=True,\n",
        "           rankdir='LR', #'LR' or 'TB'\n",
        "           expand_nested=False,\n",
        "           dpi=96,\n",
        "           layer_range=None,\n",
        "           show_layer_activations=True,\n",
        "           show_trainable=True)"
      ],
      "metadata": {
        "id": "n7s7aWtwALtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CallBacks**\n",
        "\n",
        "Callbacks no Keras são objetos que podem ser passados como parâmetros ao treinar um modelo de rede neural. Eles permitem que o modelo execute ações durante o treinamento em momentos específicos, como no início ou fim de uma época de treinamento, ou após cada lote de amostras ter sido processado."
      ],
      "metadata": {
        "id": "OjVLFnjt_yxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_compiled_model():\n",
        "  reset_seeds()\n",
        "  ...\n",
        "  return model"
      ],
      "metadata": {
        "id": "FiD_dhXvAjEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ModelCheckpoint**"
      ],
      "metadata": {
        "id": "5jeAiclmAJai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.best.hdf5\"\n",
        "checkpoint = ...\n",
        "\n",
        "model = get_compiled_model()\n",
        "\n",
        "with mlflow.start_run(run_name='callbacks_1'):\n",
        "  ..."
      ],
      "metadata": {
        "id": "MTUdRYqP_yZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EarlyStopping**"
      ],
      "metadata": {
        "id": "rbPNYKojBFmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = ...\n",
        "\n",
        "model = get_compiled_model()\n",
        "\n",
        "with mlflow.start_run(run_name='callbacks_2'):\n",
        " ..."
      ],
      "metadata": {
        "id": "_gkDrEZABFHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfRcIV5XSLQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corrigindo Overfitting\n",
        "\n",
        "Overfitting é um conceito crucial em aprendizado de máquina e estatística que descreve a situação em que um modelo se ajusta tão bem aos dados de treinamento que perde sua capacidade de generalização para novos dados. Em outras palavras, o modelo \"decora\" os dados de treinamento em vez de aprender padrões subjacentes que se aplicam a dados não vistos. Isso resulta em um desempenho deficiente quando o modelo é testado em dados que não foram usados durante o treinamento.\n",
        "\n",
        "Existem várias razões pelas quais o overfitting pode ocorrer:\n",
        "\n",
        "- Modelo muito complexo: Um modelo excessivamente complexo pode capturar até mesmo o ruído nos dados de treinamento, o que não é representativo do verdadeiro relacionamento entre as variáveis.\n",
        "\n",
        "- Dados insuficientes: Quando os dados de treinamento são escassos em relação à complexidade do modelo, o modelo pode aprender padrões específicos dos dados de treinamento que não se aplicam a novos dados.\n",
        "\n",
        "- Falta de regularização: Técnicas de regularização, como penalização L1 ou L2, são frequentemente usadas para evitar overfitting. A ausência de tais técnicas pode permitir que o modelo se ajuste demais aos dados de treinamento.\n",
        "\n",
        "Corrigir o overfitting é crucial para garantir que nosso modelo seja útil na prática"
      ],
      "metadata": {
        "id": "TqB26t0ku5IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_shape=(21,), activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "with mlflow.start_run(run_name='model_overfitting'):\n",
        "  hist = model.fit(X_train,\n",
        "                  y_train,\n",
        "                  epochs=20,\n",
        "                  validation_split=0.2,\n",
        "                  verbose=3)\n",
        "\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "phiYUngQqHr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_convergence(hist, 'loss')"
      ],
      "metadata": {
        "id": "YbzZN-H6Y33a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularização\n",
        "\n",
        "a regularização é uma técnica usada para evitar o overfitting, adicionando uma penalidade aos pesos do modelo durante o processo de otimização. Existem diferentes tipos de regularização, mas duas das mais comuns são a regularização L1 e L2.\n",
        "\n",
        "- Regularização L1 (Lasso): Na regularização L1, uma penalidade é adicionada à função de perda durante o treinamento, proporcional à magnitude absoluta dos pesos do modelo. Isso leva à \"esparsidade\" nos pesos, ou seja, alguns pesos podem se tornar exatamente zero, reduzindo a complexidade do modelo. No Keras, a regularização L1 pode ser aplicada usando a classe keras.regularizers.l1().\n",
        "\n",
        "- Regularização L2 (Ridge): Na regularização L2, uma penalidade é adicionada à função de perda durante o treinamento, proporcional à magnitude ao quadrado dos pesos do modelo. Isso desencoraja pesos grandes, tornando o modelo mais suave e menos propenso ao overfitting. No Keras, a regularização L2 pode ser aplicada usando a classe keras.regularizers.l2().\n",
        "\n",
        "Ambas as formas de regularização podem ser adicionadas como argumentos ao definir camadas em um modelo Keras."
      ],
      "metadata": {
        "id": "1wz_isDgzlNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **L1 - Lasso**"
      ],
      "metadata": {
        "id": "80yBezvLb6mC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESqXbdeDzxWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **L2 - Ridge**"
      ],
      "metadata": {
        "id": "n_-G3C1Pb_y0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tns4U-ZTcANi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout\n",
        "\n",
        "O dropout é uma técnica de regularização popular para combater o overfitting em modelos de redes neurais. Durante o treinamento, o dropout desativa aleatoriamente um determinado número de unidades (neurônios) em uma camada, definindo suas saídas como zero. Isso significa que, temporariamente, essas unidades não contribuem para o processo de treinamento e não são atualizadas durante uma etapa de otimização. O dropout é aplicado durante o treinamento, mas não durante a inferência (ou seja, quando o modelo está fazendo previsões).\n",
        "\n",
        "A ideia principal por trás do dropout é forçar a rede neural a aprender representações mais robustas e distribuídas dos dados, em vez de depender excessivamente de neurônios específicos ou correlações entre eles. Isso ajuda a reduzir a coadaptação entre os neurônios e, consequentemente, o overfitting.\n",
        "\n",
        "No Keras, o dropout pode ser facilmente aplicado às camadas usando a classe Dropout no módulo keras.layers."
      ],
      "metadata": {
        "id": "O8H2YOj9zpcp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7T75FnCzxWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo Funcional**\n",
        "\n",
        "O modelo funcional no Keras é uma API flexível e poderosa que permite construir modelos de redes neurais com topologias mais complexas do que a API sequencial oferece. Enquanto o modelo sequencial é adequado para uma pilha simples de camadas, o modelo funcional permite a criação de modelos com grafos de computação mais elaborados, incluindo múltiplas entradas, saídas e caminhos de conexão.\n",
        "\n",
        "A principal diferença entre o modelo funcional e o modelo sequencial é que, no modelo funcional, você define explicitamente as conexões entre as camadas. Isso permite que você crie arquiteturas de rede mais complexas, como modelos com múltiplas entradas ou saídas, compartilhamento de camadas e bifurcações.\n",
        "\n",
        "O modelo funcional no Keras oferece uma maneira flexível e intuitiva de construir arquiteturas de redes neurais mais complexas, permitindo criar modelos adaptados a uma ampla variedade de problemas de aprendizado profundo."
      ],
      "metadata": {
        "id": "zs8SI4yfFLvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "reset_seeds()\n",
        "inputs = ...\n",
        "fc1 = ...\n",
        "fc2 = ...\n",
        "outputs = ...\n",
        "\n",
        "model = ...\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train,\n",
        "                 y_train,\n",
        "                 epochs=10,\n",
        "                 validation_split=0.2,\n",
        "                 verbose=3)"
      ],
      "metadata": {
        "id": "CxIiua0qFLvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGnE5QuQFLvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uso de objetos**"
      ],
      "metadata": {
        "id": "Lf_amzSQFLvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(21,)))\n",
        "model.add(Dense(10, activation='relu' ))\n",
        "model.add(Dense(10, activation='relu' ))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "lr_schedule = ...\n",
        "\n",
        "opt = ...\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train,\n",
        "                 y_train,\n",
        "                 epochs=10,\n",
        "                 validation_split=0.2,\n",
        "                 verbose=3)"
      ],
      "metadata": {
        "id": "E0BRf1sxFLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoML - AutoKeras**\n",
        "\n",
        "AutoKeras é uma biblioteca de aprendizado de máquina automatizada (AutoML) de código aberto para Python, que permite a automatização de tarefas de seleção de modelo, pré-processamento de dados, ajuste de hiperparâmetros e treinamento de modelos de aprendizado de máquina de forma eficiente.\n",
        "\n",
        "O AutoKeras utiliza técnicas de busca automática de hiperparâmetros, como a busca aleatória, busca em grade e otimização bayesiana, para encontrar a melhor configuração de modelo e hiperparâmetros para um determinado problema de aprendizado de máquina. Ele suporta uma variedade de tarefas de aprendizado de máquina, incluindo classificação, regressão, segmentação de imagens e processamento de linguagem natural.\n",
        "\n",
        "Além disso, o AutoKeras possui uma interface fácil de usar que permite aos usuários treinar modelos sem a necessidade de conhecimentos avançados em aprendizado de máquina ou programação. Isso torna o AutoKeras uma ferramenta útil para usuários iniciantes e avançados que desejam economizar tempo e recursos ao treinar modelos de aprendizado de máquina de alta qualidade."
      ],
      "metadata": {
        "id": "TWO_XzoYFLvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autokeras import StructuredDataClassifier"
      ],
      "metadata": {
        "id": "nwZbMxDJFLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "dg7PjLrrFLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "RHUCX_nZFLvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}