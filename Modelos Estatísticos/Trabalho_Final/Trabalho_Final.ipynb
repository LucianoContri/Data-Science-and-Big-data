{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Predizendo Note de games na loja da Steam"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9145b60907db142c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Nome: Luciano A S Contri\n",
    "#### Matrícula: 1500596"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74feea7f022d35d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Banco de dados escolhido: Video Games on Steam [in JSON]\n",
    "    Url: https://www.kaggle.com/datasets/sujaykapadnis/games-on-steam?select=steamdb.min.json  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75512fabf58ffb7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importando Bibliotecas a serem utilizadas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a1d8c3103a47292"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import  mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:45.644047700Z",
     "start_time": "2023-12-08T14:03:45.208545600Z"
    }
   },
   "id": "36fa52dedc7013eb",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análise descritiva e preparação dos dados:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5031010264df658"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "df = pd.read_json('steamdb.json')\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:47.808227100Z",
     "start_time": "2023-12-08T14:03:45.214634Z"
    }
   },
   "id": "cd77ce33ff4417c4",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Primeiramente precisamos testar a normaliodade da nossa variável dependente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efd05d14f1858509"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "df['store_uscore'].dropna().value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title('Distribuição de Score')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico Q-Q\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(df['store_uscore'].dropna(), dist=\"norm\", plot=plt)\n",
    "plt.title('Gráfico Q-Q para store_uscore')\n",
    "plt.show()\n",
    "\n",
    "# Teste de Shapiro-Wilk\n",
    "stat, p = stats.shapiro(df['store_uscore'].dropna())\n",
    "print('Estatísticas do teste Shapiro-Wilk:', stat)\n",
    "print('P-valor:', p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:48.958169600Z",
     "start_time": "2023-12-08T14:03:47.809228100Z"
    }
   },
   "id": "8e0630cd72cdac1e",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A distribuição parece ser relativamente normal e passar no teste de shapiro, mas precisamos dar cabo de outliers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573ddb18a98b24f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Corrigindo outliers:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f19dd8657c58beb4"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "limite_frequencia = df['store_uscore'].value_counts().quantile(0.95)\n",
    "\n",
    "valores_para_manter = df['store_uscore'].value_counts()[df['store_uscore'].value_counts() < limite_frequencia].index\n",
    "df = df[df['store_uscore'].isin(valores_para_manter)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "df['store_uscore'].dropna().value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title('Distribuição de Score')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:49.806902Z",
     "start_time": "2023-12-08T14:03:48.959170200Z"
    }
   },
   "id": "b39b2838433253d",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora apenas removendo diretamente para melhorar como o 33."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8402bba90d96930f"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "df = df[df['store_uscore'] != 33]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.018072300Z",
     "start_time": "2023-12-08T14:03:49.807903300Z"
    }
   },
   "id": "ef6eaa7368e40d3a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "df['store_uscore'].dropna().value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title('Distribuição de Score')\n",
    "plt.show()\n",
    "\n",
    "# Teste de Shapiro-Wilk\n",
    "stat, p = stats.shapiro(df['store_uscore'].dropna())\n",
    "print('Estatísticas do teste Shapiro-Wilk:', stat)\n",
    "print('P-valor:', p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.668515500Z",
     "start_time": "2023-12-08T14:03:49.838900800Z"
    }
   },
   "id": "41eefabf0a867f0c",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Pronto agora sim temos uma variável normalizada, apesar"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2b19ab0f289ff5f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tratando os tipos e colunas úteis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39c439015ed70b3"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "df['published_store'] = pd.to_datetime(df['published_store'])\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.924408200Z",
     "start_time": "2023-12-08T14:03:50.670517400Z"
    }
   },
   "id": "10ad4e977e7c22f4",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    A base de dados têm bastante indices nulos e colunas que não nos dão muita informação como URL do game.\n",
    "    Precisamos retirar itens chave e manter itens que possam ter alguma relevância mas não tenham tantos NaN."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c519ad5305a06501"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# eliminando colunas que claramente têm muitos valores nulos e pouca correlação com a variável dependente.\n",
    "indices_to_drop = [0,1,2,5,6,7,8,9,10,11,14,16,17,18,19,24,26,28,30,33,36,39,40,41,42]\n",
    "\n",
    "# Obter os nomes das colunas correspondentes aos índices\n",
    "col_names_to_drop = df.columns[indices_to_drop]\n",
    "\n",
    "# Remover as colunas\n",
    "df = df.drop(columns=col_names_to_drop)\n",
    "df['Idade_do_Produto'] = (datetime.now() - df['published_store']).dt.days\n",
    "df = df.drop(columns= 'published_store')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.925410400Z",
     "start_time": "2023-12-08T14:03:50.805244500Z"
    }
   },
   "id": "ca348e3ed55b56c2",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.925410400Z",
     "start_time": "2023-12-08T14:03:50.825196300Z"
    }
   },
   "id": "a284dd4ee196be80",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "df.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.926409900Z",
     "start_time": "2023-12-08T14:03:50.854172500Z"
    }
   },
   "id": "f4c8ba5df941aa3c",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Podemos observar que 'gfq_difficulty' e 'platforms' são categóricas, já as outras são ou float ou multivaloradas."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f944d152522cb541"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "df['platforms'] = df['platforms'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.926409900Z",
     "start_time": "2023-12-08T14:03:50.889923200Z"
    }
   },
   "id": "e063bf306de44218",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tratando valores nulos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf746c59eb65913c"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:50.928412600Z",
     "start_time": "2023-12-08T14:03:50.897572500Z"
    }
   },
   "id": "41a343661e5bae5e",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    precisamos retirar todos os valores nulos da variável dependente antes de prosseguir com as demais."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa0a84168f282cf3"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "df = df.dropna(subset='store_uscore')\n",
    "print(df.isna().sum())\n",
    "print(df.shape)\n",
    "print(df.dropna().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.052837600Z",
     "start_time": "2023-12-08T14:03:50.924408200Z"
    }
   },
   "id": "453c3ae4a7587659",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Podemos observar que retirando todos valores nulos, nosso dataset cai muito, podemos tentar preencher com a média os valores em float."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647b196dee218f05"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Lista de colunas do tipo float64 para substituir NaNs pela média\n",
    "colunas_float64 = ['full_price', 'current_price', 'achievements', 'gfq_rating',\n",
    "                   'gfq_length', 'stsp_owners', 'stsp_mdntime', 'hltb_single',\n",
    "                   'hltb_complete', 'meta_score', 'meta_uscore', 'igdb_score',\n",
    "                   'igdb_uscore', 'igdb_popularity', 'Idade_do_Produto']\n",
    "\n",
    "# Substituindo NaNs por médias nas colunas especificadas\n",
    "for coluna in colunas_float64:\n",
    "    media = df[coluna].mean()\n",
    "    df[coluna] = df[coluna].fillna(media)\n",
    "print(df.isna().sum())\n",
    "print(df.shape)\n",
    "print(df.dropna().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.054839100Z",
     "start_time": "2023-12-08T14:03:50.971685200Z"
    }
   },
   "id": "bfff9396a1977ae9",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Já melhorou bastante mas como categories, genres e tags são multivalorados com interseção entre si podemos ao expandi-los tornar todos tags com colunas unicas booleanas excluindo as 3, portanto precisamos tratar apenas gfq_difficulty."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7e7f792cdba0d7e"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "df['gfq_difficulty'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.054839100Z",
     "start_time": "2023-12-08T14:03:51.031510900Z"
    }
   },
   "id": "d0b1222092004a29",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos considerar que \"Simple\" é o nível de dificuldade mais baixo, seguido por \"Easy\", \"Just Right\" como um nível intermediário, \"Tough\" como mais difícil e \"Unforgiving\" como o mais difícil.\n",
    "    \n",
    "Com isso podemos categorizar a coluna gfq_difficulty em um float de 1 a 9:\n",
    "1 - Simple\n",
    "2 - Simple-Easy\n",
    "3 - Easy\n",
    "4 - Easy-Just Right\n",
    "5 - Just Right\n",
    "6 - Just Right-Tough\n",
    "7 - Tough\n",
    "8 - Tough-Unforgiving\n",
    "9 - Unforgiving"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9222c9a7549c0a84"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "mapeamento_dificuldade = {\n",
    "    \"Simple\": 1,\n",
    "    \"Simple-Easy\": 2,\n",
    "    \"Easy\": 3,\n",
    "    \"Easy-Just Right\": 4,\n",
    "    \"Just Right\": 5,\n",
    "    \"Just Right-Tough\": 6,\n",
    "    \"Tough\": 7,\n",
    "    \"Tough-Unforgiving\": 8,\n",
    "    \"Unforgiving\": 9\n",
    "}\n",
    "\n",
    "# Aplicando o mapeamento à coluna gfq_difficulty\n",
    "df['gfq_difficulty'] = df['gfq_difficulty'].map(mapeamento_dificuldade)\n",
    "df['gfq_difficulty'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.055840200Z",
     "start_time": "2023-12-08T14:03:51.040389300Z"
    }
   },
   "id": "c96448d2478ce5a8",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com isso agora podemos inferir a média nos índices faltantes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f4e897760a00c25"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "media = round(df['gfq_difficulty'].mean())\n",
    "df['gfq_difficulty'] = df['gfq_difficulty'].fillna(media)\n",
    "print(df.isna().sum())\n",
    "print(df.shape)\n",
    "print(df.dropna().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.196256300Z",
     "start_time": "2023-12-08T14:03:51.049836500Z"
    }
   },
   "id": "ed8f101f8b0eeaaa",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3ac3355e890309d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    " Tudo certo, agora vamos para as multivaloradas como podemos ver embaixo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8daa705e2685b1a1"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "df['genres'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.197257600Z",
     "start_time": "2023-12-08T14:03:51.093892500Z"
    }
   },
   "id": "9cbf62866dbf388d",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    As colunas ['tags', 'categories', 'genres'] são multivaloradas, para analisarmos cada item\n",
    "    precisamos expandir em mais colunas."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874f28b8fc6ae12c"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "df['categories'] = df['categories'].apply(lambda x: x.split(',') if x is not None else [])\n",
    "df['genres'] = df['genres'].apply(lambda x: x.split(',') if x is not None else [])\n",
    "df['tags'] = df['tags'].apply(lambda x: x.split(',') if x is not None else [])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.350755700Z",
     "start_time": "2023-12-08T14:03:51.110665400Z"
    }
   },
   "id": "37719b5fd799599",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Claramente alguns itens de cada tabela se sobrepõe, o quê criaria redundância, então temos que trablhar com conjuntos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d85f0cde0ef7cb25"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Instanciar o MultiLabelBinarizer para fazer o one-hot encoding\n",
    "combined_labels = df.apply(lambda x: set(x['categories'] + x['genres'] + x['tags']), axis=1)\n",
    "\n",
    "# Instanciar o MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Aplicar o one-hot encoding\n",
    "combined_encoded = pd.DataFrame(mlb.fit_transform(combined_labels), columns=mlb.classes_, index=df.index)\n",
    "\n",
    "# Concatenar com o DataFrame original\n",
    "df_encoded = pd.concat([df, combined_encoded], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:51.779403300Z",
     "start_time": "2023-12-08T14:03:51.348753900Z"
    }
   },
   "id": "a71a07f085e698f2",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Agora com essas colunas criadas foi observado 2 colunas com nomes ligeiramente diferentes mas que também são redundantes além de podermos excluir as originais 'tags', 'categories' e 'genres'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d6a6d6e38e40eed"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "df_encoded['Multi'] = df_encoded['Multi-player'] | df_encoded['Multiplayer']\n",
    "df_encoded = df_encoded.drop(columns=['Multiplayer', 'Multi-player','tags', 'categories', 'genres'])\n",
    "print(df_encoded.info())\n",
    "print(df_encoded.shape)\n",
    "print(df_encoded.dropna().shape)\n",
    "df_encoded = df_encoded.dropna()\n",
    "df_encoded.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:52.009610600Z",
     "start_time": "2023-12-08T14:03:51.779403300Z"
    }
   },
   "id": "813ec174f198abd2",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preservados quase todos os indices da tabela agora podemos seguir adiante."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a1cece965d58fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análise de correlação"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d4bbb337840a4a"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "corr_matrix = df_encoded.corr()\n",
    "\n",
    "# Filtrar colunas com correlação acima de um limiar (0.1 neste caso)\n",
    "# Verificar primeiro se as colunas estão presentes no DataFrame\n",
    "cols_to_keep = corr_matrix.columns[corr_matrix.abs()['store_uscore'] > 0.15]\n",
    "\n",
    "# Criar uma nova matriz de correlação apenas com as colunas filtradas\n",
    "filtered_corr_matrix = df_encoded[cols_to_keep].corr()\n",
    "\n",
    "# Usar seaborn para criar um heatmap da matriz de correlação filtrada\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(filtered_corr_matrix, annot=True, fmt=\".2f\", cmap='bwr', center= 0.05)\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:57.663927100Z",
     "start_time": "2023-12-08T14:03:52.008608300Z"
    }
   },
   "id": "1588a5eb8ed959",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " Observando a matriz de correlação, está claro que a maioria São fracas e a maior é de 0.41 o que indica que temos que fazer um modelo com várias variáveis independentes para termos sucesso."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e22b579b2ec1930c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Regressão linear ou polinomial?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fff57d60b272507"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Regressão linear simples:\n",
    "   com a variável de maior correlação"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7eaa5ecd9d3c1cf"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "X = df_encoded['igdb_uscore']\n",
    "y = df_encoded['store_uscore']       # Variável dependente\n",
    "X_sm = sm.add_constant(X)\n",
    "model_sm = sm.OLS(y, X_sm).fit()\n",
    "print(model_sm.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:57.683662200Z",
     "start_time": "2023-12-08T14:03:57.663927100Z"
    }
   },
   "id": "7a7baa563c3f9847",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "y_pred = model_sm.predict(X_sm)\n",
    "Residuos = y - y_pred\n",
    "shapiro_test = stats.shapiro(Residuos)\n",
    "print(\"Shapiro-Wilk Modelo RLS:\", shapiro_test)\n",
    "bp_test = sm.stats.diagnostic.het_breuschpagan(Residuos, model_sm.model.exog)\n",
    "print(\"Breusch-Pagan Modelo RLS:\", bp_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:03:57.687172400Z",
     "start_time": "2023-12-08T14:03:57.676583300Z"
    }
   },
   "id": "28b867dc81ef62b8",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Não passou em nenhum teste de resíduos. \n",
    "Insatisfatório, pode melhorar."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90118f7c836aa875"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Regressão linear com multiplas variáveis:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e4ef27f3fb2e164"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "r_ajustados_modelo = []\n",
    "f_statistics_modelo  = []\n",
    "limite = []\n",
    "residuos_normais = []\n",
    "for i in range(15):\n",
    "    corr_matrix = df_encoded.corr(numeric_only=True)\n",
    "    multi = 0.05 + (0.01 * i)\n",
    "    limite.append(multi)\n",
    "    cols_to_keep = corr_matrix.index[corr_matrix.abs()['store_uscore'] > multi]\n",
    "    cols_to_keep = cols_to_keep.drop('store_uscore')  # Remover a coluna 'score' da lista\n",
    "    X = df_encoded[cols_to_keep]  # Variáveis independentes\n",
    "    y = df_encoded['store_uscore']       # Variável dependente\n",
    "    X_sm = sm.add_constant(X)\n",
    "    model_sm = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "    y_pred = model_sm.predict(X_sm)\n",
    "    Residuos = y - y_pred\n",
    "    bp_test = sm.stats.diagnostic.het_breuschpagan(Residuos, model_sm.model.exog)\n",
    "    if bp_test[2] > 0.05:\n",
    "        residuos_normais.append(multi)\n",
    "\n",
    "    adj_r_squared = model_sm.rsquared_adj\n",
    "    f_statistic = model_sm.fvalue\n",
    "\n",
    "    r_ajustados_modelo.append(adj_r_squared)\n",
    "    f_statistics_modelo.append(f_statistic)\n",
    "print('Modelos que passaram no teste de resíduos de pagan:\\n')\n",
    "print(residuos_normais)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:05:17.225909200Z",
     "start_time": "2023-12-08T14:03:57.686171400Z"
    }
   },
   "id": "8869f961624a3669",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Primeiro subplot para R-quadrado ajustado\n",
    "plt.subplot(1, 2, 1)  # (linhas, colunas, índice do subplot)\n",
    "plt.plot(limite,r_ajustados_modelo, label='R-quadrado Ajustado', color='blue', marker='o')\n",
    "plt.title('R-quadrado Ajustado')\n",
    "plt.xlabel('Iteração (Limiar de Correlação)')\n",
    "plt.ylabel('R-quadrado Ajustado')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Segundo subplot para F-statistic\n",
    "plt.subplot(1, 2, 2)  # (linhas, colunas, índice do subplot)\n",
    "plt.plot(limite,f_statistics_modelo, label='F-statistic', color='red', marker='x')\n",
    "plt.title('F-statistic')\n",
    "plt.xlabel('Iteração (Limiar de Correlação)')\n",
    "plt.ylabel('F-statistic')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta o layout para manter tudo organizado\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:05:17.683178600Z",
     "start_time": "2023-12-08T14:05:17.227911Z"
    }
   },
   "id": "f16daed6bd278844",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "QQ-PLOT do maior R-ajustado e maior F-statistic"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0da96168cd7291c"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "cols_to_keep = corr_matrix.index[corr_matrix.abs()['store_uscore'] > 0.05]\n",
    "cols_to_keep = cols_to_keep.drop('store_uscore')  # Remover a coluna 'score' da lista\n",
    "X = df_encoded[cols_to_keep]  # Variáveis independentes\n",
    "y = df_encoded['store_uscore']       # Variável dependente\n",
    "X_sm = sm.add_constant(X)\n",
    "model_sm = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "y_pred = model_sm.predict(X_sm)\n",
    "Residuos_r_maior = y - y_pred\n",
    "bp_test = sm.stats.diagnostic.het_breuschpagan(Residuos_r_maior, model_sm.model.exog)\n",
    "\n",
    "print(bp_test)\n",
    "print(model_sm.summary())\n",
    "\n",
    "cols_to_keep = corr_matrix.index[corr_matrix.abs()['store_uscore'] > 0.18]\n",
    "cols_to_keep = cols_to_keep.drop('store_uscore')  # Remover a coluna 'score' da lista\n",
    "X = df_encoded[cols_to_keep]     # Variável dependente\n",
    "X_sm = sm.add_constant(X)\n",
    "model_sm = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "y_pred = model_sm.predict(X_sm)\n",
    "Residuos_r_menor = y - y_pred\n",
    "bp_test = sm.stats.diagnostic.het_breuschpagan(Residuos_r_menor, model_sm.model.exog)\n",
    "\n",
    "print(bp_test)\n",
    "print(model_sm.summary())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfico Q-Q para o primeiro modelo\n",
    "plt.subplot(1, 2, 1)  # (linhas, colunas, índice do subplot)\n",
    "sm.qqplot(Residuos_r_maior, line='s', ax=plt.gca())\n",
    "plt.title('Gráfico Q-Q do Modelo 1')\n",
    "\n",
    "# Gráfico Q-Q para o segundo modelo\n",
    "plt.subplot(1, 2, 2)  # (linhas, colunas, índice do subplot)\n",
    "sm.qqplot(Residuos_r_menor, line='s', ax=plt.gca())\n",
    "plt.title('Gráfico Q-Q do Modelo 2')\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:05:18.404903400Z",
     "start_time": "2023-12-08T14:05:17.683178600Z"
    }
   },
   "id": "be11975ae4219dc1",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ainda aparenta um R-ajustado baixo. O modelo explica pouco mesmo com residuos melhorando um pouco com f-stat maior."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f50cc3676afa9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Regressão Polinomial:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd206d9b71c885a9"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "cols_to_keep = corr_matrix.index[corr_matrix.abs()['store_uscore'] > 0.1]\n",
    "cols_to_keep = cols_to_keep.drop('store_uscore')  # Remover a coluna 'score' da lista\n",
    "X = df_encoded[cols_to_keep]  # Variáveis independentes\n",
    "y = df_encoded['store_uscore']\n",
    "\n",
    "r_ajustados_modelo_poli = []\n",
    "f_statistics_modelo_poli = []\n",
    "residuos_normais = []\n",
    "degrees = [1,2,3,4]\n",
    "for degree in degrees:  # Graus 1 a 5\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    X_sm_poly = sm.add_constant(X_poly)\n",
    "    model_sm_poly = sm.OLS(y, X_sm_poly).fit()\n",
    "\n",
    "    # Extrair R² ajustado e F-statistic\n",
    "    adj_r_squared = model_sm_poly.rsquared_adj\n",
    "    f_statistic = model_sm_poly.fvalue\n",
    "    r_ajustados_modelo_poli.append(adj_r_squared)\n",
    "    f_statistics_modelo_poli.append(f_statistic)\n",
    "\n",
    "    y_pred = model_sm_poly.predict(X_sm_poly)\n",
    "    Residuos = y - y_pred\n",
    "    bp_test = sm.stats.diagnostic.het_breuschpagan(Residuos, model_sm.model.exog)\n",
    "    if bp_test[2] > 0.05:\n",
    "        residuos_normais.append(degree)\n",
    "print('Grau polinomial que passaram no teste de pagan:\\n')\n",
    "print(residuos_normais)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Primeiro subplot para R-quadrado ajustado\n",
    "plt.subplot(1, 2, 1)  # (linhas, colunas, índice do subplot)\n",
    "plt.plot(r_ajustados_modelo_poli, label='R-quadrado Ajustado', color='blue', marker='o')\n",
    "plt.title('R-quadrado Ajustado')\n",
    "plt.xlabel('Grau')\n",
    "plt.ylabel('R-quadrado Ajustado')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Segundo subplot para F-statistic\n",
    "plt.subplot(1, 2, 2)  # (linhas, colunas, índice do subplot)\n",
    "plt.plot(f_statistics_modelo_poli, label='F-statistic', color='red', marker='x')\n",
    "plt.title('F-statistic')\n",
    "plt.xlabel('Grau')\n",
    "plt.ylabel('F-statistic')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta o layout para manter tudo organizado\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:05:54.993834100Z",
     "start_time": "2023-12-07T22:05:15.550949200Z"
    }
   },
   "id": "39591cca5d803551",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55cca8891700268d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "poly = PolynomialFeatures(4)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_sm_poly = sm.add_constant(X_poly)\n",
    "model_sm_poly = sm.OLS(y, X_sm_poly).fit()\n",
    "\n",
    "y_pred = model_sm_poly.predict(X_sm_poly)\n",
    "Residuos = y - y_pred\n",
    "bp_test = sm.stats.diagnostic.het_breuschpagan(Residuos, model_sm.model.exog)\n",
    "print(bp_test)\n",
    "print(model_sm_poly.summary())\n",
    "\n",
    "\n",
    "sm.qqplot(Residuos, line='s')\n",
    "plt.title('Gráfico Q-Q dos Resíduos')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:06:34.293622200Z",
     "start_time": "2023-12-07T22:05:54.968304800Z"
    }
   },
   "id": "9707b056cb4434f9",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Como podemos observar a correlação dos dados são fracas, testados a Regressão linear simples, com variáveis multiplas e polinomial, a polinomial se saiu melhor.<br> já a Regressão linear simples sequer passou nos testes de residuo o que indica heterocedasticidade."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c174aa8676d261c5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "63baa947b0421bc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
