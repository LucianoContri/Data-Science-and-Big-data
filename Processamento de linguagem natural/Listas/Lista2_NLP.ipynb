{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lista 2 - pré-processamento**\n",
        "\n",
        "Para resolução da lista utilize os slides do material de pré-processamento e os códigos de pré-processamento e wordcloud.\n",
        "\n",
        "## **Exercício**:\n",
        "Para as pipelines de pré-processamento desenhadas abaixo faça:\n",
        "1. Escreva um código que realize o pré-processamento e que em cada print seja mostrado o tamanho do vocabulário (utilizar as funções print, set e len)\n",
        "2. Após executar o pré-processamento no texto plot as 20 mais frequentes.\n",
        "\n",
        "\n",
        "### 1ª - Pipeline\n",
        "* Tokenizar as strings utilizando nltk\n",
        "* Passar as palavras para minúsculo\n",
        "* Remover stopwords\n",
        "* Substituir números por NUMERO\n",
        "* Remover pontos\n",
        "* Remover acentos"
      ],
      "metadata": {
        "id": "bAizAw07mNQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zxyWN0AmK-p"
      },
      "outputs": [],
      "source": [
        "##Texto para utilizar nas pipelines:\n",
        "import wikipedia\n",
        "wikipedia.set_lang(\"pt\")\n",
        "bh = wikipedia.page(\"Belo Horizonte\")\n",
        "corpus = bh.content ##este é o texto que será o input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2ª Pipeline\n",
        "* Tokenizar as strings utilizando nltk\n",
        "* Passar as palavras para minúsculo\n",
        "* Remover acentos\n",
        "* Remover stopwords\n",
        "* Substituir números por NUMERO\n",
        "* Remover pontos\n",
        "* Realizar stemming"
      ],
      "metadata": {
        "id": "S1EKIo2N84ah"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0MinEEUt9CGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3ª Pipeline\n",
        "* Tokenizar as strings utilizando nltk\n",
        "* Passar as palavras para minúsculo\n",
        "* Remover acentos\n",
        "* Remover números\n",
        "* Remover pontos\n",
        "* Realizar lemmantization"
      ],
      "metadata": {
        "id": "DWiagoCm88M_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6NoXXeL9BdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4ª Pipeline\n",
        "* Tokenizar as strings utilizando nltk\n",
        "* Passar as palavras para minúsculo\n",
        "* Remover stopwords\n",
        "* Remover números\n",
        "* Remover pontos\n",
        "* Realizar lemmantization"
      ],
      "metadata": {
        "id": "-q5Luqbp9BE1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZUpyj6_jU3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}