{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Lista 2 - pré-processamento**\n",
    "\n",
    "Para resolução da lista utilize os slides do material de pré-processamento e os códigos de pré-processamento e wordcloud.\n",
    "\n",
    "## **Exercício**:\n",
    "Para as pipelines de pré-processamento desenhadas abaixo faça:\n",
    "1. Escreva um código que realize o pré-processamento e que em cada print seja mostrado o tamanho do vocabulário (utilizar as funções print, set e len)\n",
    "2. Após executar o pré-processamento no texto plot as 20 mais frequentes.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "bAizAw07mNQ2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2zxyWN0AmK-p",
    "ExecuteTime": {
     "end_time": "2024-06-16T15:50:43.128726Z",
     "start_time": "2024-06-16T15:50:38.558357Z"
    }
   },
   "source": [
    "##Texto para utilizar nas pipelines:\n",
    "import wikipedia\n",
    "wikipedia.set_lang(\"pt\")\n",
    "bh = wikipedia.page(\"Belo Horizonte\")\n",
    "corpus = bh.content ##este é o texto que será o input"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:50:51.394554Z",
     "start_time": "2024-06-16T15:50:46.102657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importar bibliotecas\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# spacy para stemming e lemmantization\n",
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:50:54.121355Z",
     "start_time": "2024-06-16T15:50:53.864058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Downloads necessários\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lucia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lucia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Lucia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lucia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1ª - Pipeline\n",
    "* Tokenizar as strings utilizando nltk\n",
    "* Passar as palavras para minúsculo\n",
    "* Remover stopwords\n",
    "* Substituir números por NUMERO\n",
    "* Remover pontos\n",
    "* Remover acentos"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:51:00.666064Z",
     "start_time": "2024-06-16T15:51:00.520538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenização\n",
    "tokens = word_tokenize(corpus, language='portuguese')\n",
    "\n",
    "# passar as palavras para minúsculo\n",
    "tokens = [word.lower() for word in tokens]\n",
    "\n",
    "# remover stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# substituir números por NUMERO\n",
    "tokens = ['NUMERO' if word.isdigit() else word for word in tokens]\n",
    "\n",
    "# remover pontos\n",
    "tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "# remover acentos\n",
    "import unidecode\n",
    "tokens_pipeline_1 = [unidecode.unidecode(word) for word in tokens]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2ª Pipeline\n",
    "* Tokenizar as strings utilizando nltk\n",
    "* Passar as palavras para minúsculo\n",
    "* Remover acentos\n",
    "* Remover stopwords\n",
    "* Substituir números por NUMERO\n",
    "* Remover pontos\n",
    "* Realizar stemming"
   ],
   "metadata": {
    "id": "S1EKIo2N84ah"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#tokenização\n",
    "tokens = word_tokenize(corpus, language='portuguese')\n",
    "\n",
    "# passar as palavras para minúsculo\n",
    "tokens = [word.lower() for word in tokens]\n",
    "\n",
    "# remover acentos\n",
    "tokens = [unidecode.unidecode(word) for word in tokens]\n",
    "\n",
    "# remover stopwords\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# substituir números por NUMERO\n",
    "tokens = ['NUMERO' if word.isdigit() else word for word in tokens]\n",
    "\n",
    "# remover pontos\n",
    "tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "# realizar stemming com nltk\n",
    "from nltk.stem import RSLPStemmer\n",
    "stemmer = RSLPStemmer()\n",
    "tokens_pipeline_2 = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "# realizar stemming com spacy\n",
    "tokens_pipeline_2_spacy = [word.lemma_ for word in nlp(\" \".join(tokens))]\n"
   ],
   "metadata": {
    "id": "0MinEEUt9CGh",
    "ExecuteTime": {
     "end_time": "2024-06-16T15:51:02.319464Z",
     "start_time": "2024-06-16T15:51:00.669535Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3ª Pipeline\n",
    "* Tokenizar as strings utilizando nltk\n",
    "* Passar as palavras para minúsculo\n",
    "* Remover acentos\n",
    "* Remover números\n",
    "* Remover pontos\n",
    "* Realizar lemmantization"
   ],
   "metadata": {
    "id": "DWiagoCm88M_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# tokenização\n",
    "tokens = word_tokenize(corpus, language='portuguese')\n",
    "\n",
    "# passar as palavras para minúsculo\n",
    "tokens = [word.lower() for word in tokens]\n",
    "\n",
    "# remover acentos\n",
    "tokens = [unidecode.unidecode(word) for word in tokens]\n",
    "\n",
    "# remover números\n",
    "tokens = [word for word in tokens if not word.isdigit()]\n",
    "\n",
    "# remover pontos\n",
    "tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "# realizar lemmantization com nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens_pipeline_3 = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "# realizar lemmantization com spacy\n",
    "tokens_pipeline_3_spacy = [word.lemma_ for word in nlp(\" \".join(tokens))]"
   ],
   "metadata": {
    "id": "S6NoXXeL9BdV",
    "ExecuteTime": {
     "end_time": "2024-06-16T15:51:05.438834Z",
     "start_time": "2024-06-16T15:51:02.321533Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 4ª Pipeline\n",
    "* Tokenizar as strings utilizando nltk\n",
    "* Passar as palavras para minúsculo\n",
    "* Remover stopwords\n",
    "* Remover números\n",
    "* Remover pontos\n",
    "* Realizar lemmantization"
   ],
   "metadata": {
    "id": "-q5Luqbp9BE1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# tokenização\n",
    "tokens = word_tokenize(corpus, language='portuguese')\n",
    "\n",
    "# passar as palavras para minúsculo\n",
    "tokens = [word.lower() for word in tokens]\n",
    "\n",
    "# remover stopwords\n",
    "tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# remover números\n",
    "tokens = [word for word in tokens if not word.isdigit()]\n",
    "\n",
    "# remover pontos\n",
    "tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "# realizar lemmantization\n",
    "tokens_pipeline_4 = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "# realizar lemmantization com spacy\n",
    "tokens_pipeline_4_spacy = [word.lemma_ for word in nlp(\" \".join(tokens))]\n"
   ],
   "metadata": {
    "id": "uZUpyj6_jU3f",
    "ExecuteTime": {
     "end_time": "2024-06-16T15:51:06.353128Z",
     "start_time": "2024-06-16T15:51:05.439846Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:52:23.640791Z",
     "start_time": "2024-06-16T15:52:23.628728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"Tamanho do vocabulário:\")\n",
    "print(f'Pipeline 1 NLTK: {len(set(tokens_pipeline_1))}')\n",
    "print(f'Pipeline 2 NLTK: {len(set(tokens_pipeline_2))}')\n",
    "print(f'Pipeline 3 NLTK: {len(set(tokens_pipeline_3))}')\n",
    "print(f'Pipeline 4 NLTK: {len(set(tokens_pipeline_4))}')\n",
    "\n",
    "print(f'Pipeline 2 SPACY Stemm: {len(set(tokens_pipeline_2_spacy))}')\n",
    "print(f'Pipeline 3 SPACY  Lemm: {len(set(tokens_pipeline_3_spacy))}')\n",
    "print(f'Pipeline 4 SPACY  Lemm: {len(set(tokens_pipeline_4_spacy))}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário:\n",
      "Pipeline 1 NLTK: 3387\n",
      "Pipeline 2 NLTK: 2360\n",
      "Pipeline 3 NLTK: 3433\n",
      "Pipeline 4 NLTK: 3367\n",
      "Pipeline 2 SPACY Stemm: 2993\n",
      "Pipeline 3 SPACY  Lemm: 2893\n",
      "Pipeline 4 SPACY  Lemm: 2873\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"20 mais frequentes:\")\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Converter a lista para um DataFrame\n",
    "df_pipeline_1_nltk = pd.DataFrame([dict(Counter(tokens_pipeline_1).most_common(20))])\n",
    "df_pipeline_2_nltk = pd.DataFrame([dict(Counter(tokens_pipeline_2).most_common(20))])\n",
    "df_pipeline_3_nltk = pd.DataFrame([dict(Counter(tokens_pipeline_3).most_common(20))])\n",
    "df_pipeline_4_nltk = pd.DataFrame([dict(Counter(tokens_pipeline_4).most_common(20))])"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:37.197537Z",
     "start_time": "2024-06-16T16:14:37.185147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Pipeline 1 NLTK\")\n",
    "df_pipeline_1_nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 1 NLTK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   NUMERO  horizonte  belo  cidade  minas  capital  gerais  municipio  brasil  \\\n",
       "0     566        152   150     109     66       51      45         42      33   \n",
       "\n",
       "   regiao  area  mil  estado  habitantes  ainda  populacao  grande  maior  \\\n",
       "0      32    32   32      28          28     28         27      27     26   \n",
       "\n",
       "   rio  nacional  \n",
       "0   26        26  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>horizonte</th>\n",
       "      <th>belo</th>\n",
       "      <th>cidade</th>\n",
       "      <th>minas</th>\n",
       "      <th>capital</th>\n",
       "      <th>gerais</th>\n",
       "      <th>municipio</th>\n",
       "      <th>brasil</th>\n",
       "      <th>regiao</th>\n",
       "      <th>area</th>\n",
       "      <th>mil</th>\n",
       "      <th>estado</th>\n",
       "      <th>habitantes</th>\n",
       "      <th>ainda</th>\n",
       "      <th>populacao</th>\n",
       "      <th>grande</th>\n",
       "      <th>maior</th>\n",
       "      <th>rio</th>\n",
       "      <th>nacional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>566</td>\n",
       "      <td>152</td>\n",
       "      <td>150</td>\n",
       "      <td>109</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:24.156889Z",
     "start_time": "2024-06-16T16:14:24.142828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Pipeline 2 NLTK\")\n",
    "df_pipeline_2_nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 2 NLTK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   numer  bel  horizont  cidad  min  brasil  capit  sao  municipi  geral  are  \\\n",
       "0    578  152       152    125  106      67     61   58        52     50   48   \n",
       "\n",
       "   grand  outr  tamb  habit  ano  mai  est  nov  regia  \n",
       "0     46    46    44     38   38   34   33   33     32  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numer</th>\n",
       "      <th>bel</th>\n",
       "      <th>horizont</th>\n",
       "      <th>cidad</th>\n",
       "      <th>min</th>\n",
       "      <th>brasil</th>\n",
       "      <th>capit</th>\n",
       "      <th>sao</th>\n",
       "      <th>municipi</th>\n",
       "      <th>geral</th>\n",
       "      <th>are</th>\n",
       "      <th>grand</th>\n",
       "      <th>outr</th>\n",
       "      <th>tamb</th>\n",
       "      <th>habit</th>\n",
       "      <th>ano</th>\n",
       "      <th>mai</th>\n",
       "      <th>est</th>\n",
       "      <th>nov</th>\n",
       "      <th>regia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>578</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>125</td>\n",
       "      <td>106</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:24.182622Z",
     "start_time": "2024-06-16T16:14:24.168738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Pipeline 3 NLTK\")\n",
    "df_pipeline_3_nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 3 NLTK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    de    e    a    o   do   da   em  que  com  horizonte  belo   no   na  \\\n",
       "0  993  613  605  438  431  394  259  198  153        152   150  150  122   \n",
       "\n",
       "   cidade  para  uma  por  um  como  mais  \n",
       "0     109    92   89   87  85    83    76  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>o</th>\n",
       "      <th>do</th>\n",
       "      <th>da</th>\n",
       "      <th>em</th>\n",
       "      <th>que</th>\n",
       "      <th>com</th>\n",
       "      <th>horizonte</th>\n",
       "      <th>belo</th>\n",
       "      <th>no</th>\n",
       "      <th>na</th>\n",
       "      <th>cidade</th>\n",
       "      <th>para</th>\n",
       "      <th>uma</th>\n",
       "      <th>por</th>\n",
       "      <th>um</th>\n",
       "      <th>como</th>\n",
       "      <th>mais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993</td>\n",
       "      <td>613</td>\n",
       "      <td>605</td>\n",
       "      <td>438</td>\n",
       "      <td>431</td>\n",
       "      <td>394</td>\n",
       "      <td>259</td>\n",
       "      <td>198</td>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>122</td>\n",
       "      <td>109</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:24.222518Z",
     "start_time": "2024-06-16T16:14:24.209352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Pipeline 4 NLTK\")\n",
    "df_pipeline_4_nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 4 NLTK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   horizonte  belo  cidade  mina  capital  gerais  município  ano  brasil  \\\n",
       "0        152   150     109    67       51      45         42   38      33   \n",
       "\n",
       "   região  área  mil  estado  habitantes  ainda  população  grande  maior  \\\n",
       "0      32    32   32      28          28     28         27      27     26   \n",
       "\n",
       "   rio  nacional  \n",
       "0   26        26  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizonte</th>\n",
       "      <th>belo</th>\n",
       "      <th>cidade</th>\n",
       "      <th>mina</th>\n",
       "      <th>capital</th>\n",
       "      <th>gerais</th>\n",
       "      <th>município</th>\n",
       "      <th>ano</th>\n",
       "      <th>brasil</th>\n",
       "      <th>região</th>\n",
       "      <th>área</th>\n",
       "      <th>mil</th>\n",
       "      <th>estado</th>\n",
       "      <th>habitantes</th>\n",
       "      <th>ainda</th>\n",
       "      <th>população</th>\n",
       "      <th>grande</th>\n",
       "      <th>maior</th>\n",
       "      <th>rio</th>\n",
       "      <th>nacional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>150</td>\n",
       "      <td>109</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:51:06.399137Z",
     "start_time": "2024-06-16T15:51:06.394919Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 11
  }
 ]
}
