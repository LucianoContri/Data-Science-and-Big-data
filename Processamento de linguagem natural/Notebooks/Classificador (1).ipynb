{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classificação de Documentos\n",
        "\n",
        "A clssificação de documentos é muito útil em vários aspectos. Um dos tipos de classificação de texto é a análise de sentimentos.\n",
        "\n",
        "A fim de ilustrar a classificação de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa.\n",
        "\n",
        "## Carregando o embedding e os dados"
      ],
      "metadata": {
        "id": "J6e5fLiZS8nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXAMuXYrW06o",
        "outputId": "6f88b805-68a4-47d8-ca5a-1dabc7a198db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/235.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.7\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2023.7.22)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "metadata": {
        "id": "Gi9S_uWeWCZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opção 1 -> montar o drive no colab e acessar o arquivo de embedding do drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#opção 2 -> fazer download e fazer upload por aqui\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwtuxwvYS8Uv",
        "outputId": "b559f6bb-1e8c-40bd-e1fe-dff51836343e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "path='ptwiki_20180420_100d.txt.bz2'\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(path, binary=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_obUVTjV7G5",
        "outputId": "30ddb68f-140f-4577-b140-097205076f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 47s, sys: 501 ms, total: 1min 48s\n",
            "Wall time: 1min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamento dos dados\n",
        "\n",
        "1. Transforme a variavel alvo (sentiment) em uma variável binaria\n",
        "2. Faço o seguinte pré-processamento no texto:\n",
        "  1. tokenize as expressões usando regex \"\\w+(?:'\\w+)?|[^\\w\\s]\"\n",
        "  2. Passe tudo para minusculo\n",
        "  3. Remova stopwords\n",
        "  4. Remova pontuação\n",
        "  5. Remova números\n",
        "\n",
        "  Faça duas funções de pré-processamento uma que retorne a frase processada e uma que retorne uma lista com os tokens."
      ],
      "metadata": {
        "id": "HLLT7T0iTu96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solução"
      ],
      "metadata": {
        "id": "D2mu4HjX9BEM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quS105yz9TKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag-of-word\n",
        "\n",
        "Crie uma representação bag-of-words do texto."
      ],
      "metadata": {
        "id": "kduTo4PrUHR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solução"
      ],
      "metadata": {
        "id": "DDbmgz3w9EDv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ef4HlrL9UV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding\n",
        "\n",
        "Utilizando o embedding crie uma representação de embedding com a média das representações das palavras do texto."
      ],
      "metadata": {
        "id": "hv9BDAW1UZyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solução"
      ],
      "metadata": {
        "id": "UEvUNZj-9GqO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uac0_ZCr9V7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento\n",
        "\n",
        "Separe o banco de bag of words em treino e teste e treine um modelo de regressão Logistica, qual a avaliação desse modelo?"
      ],
      "metadata": {
        "id": "FAAjfdIiU54d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solução"
      ],
      "metadata": {
        "id": "0cwLF5Ga9H6H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjPHV1ug9XW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "\n",
        "Separe o banco de embedding em treino e teste e treine um modelo de regressão Logistica, qual a avaliação desse modelo?"
      ],
      "metadata": {
        "id": "lCCLnh-6VDCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solução"
      ],
      "metadata": {
        "id": "e6j_0HQX9JIa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaFMnfWV9Zb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de sentimentos\n",
        "\n",
        "Quando o objetivo é realizar análise de sentimentos podemos treinar o nosso proprio modelo ou utilizar ferramentas já feitas. Exemplo: Vader.\n",
        "\n",
        "O VADER (Valence Aware Dictionary e sEntiment Reasoner) é uma ferramenta de análise de sentimentos baseada em regras e léxico, especificamente identifica os sentimentos expressos nas mídias sociais.\n",
        "\n",
        "- positive sentiment: compound score >= 0.05\n",
        "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
        "- negative sentiment: compound score <= -0.05\n",
        "\n",
        "Mais informações: https://github.com/cjhutto/vaderSentiment"
      ],
      "metadata": {
        "id": "AKNj35JXVY34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "-FtJR2x4Voit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "9wIOnjcrVqgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto_neg = df.loc[0, \"text_en\"]\n",
        "texto_pos = df.loc[49431, \"text_en\"]"
      ],
      "metadata": {
        "id": "SWVKxQFRVsQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.polarity_scores(texto_neg)"
      ],
      "metadata": {
        "id": "bPuneH6MVuXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer.polarity_scores(texto_pos)"
      ],
      "metadata": {
        "id": "3vdErQguVuQR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}